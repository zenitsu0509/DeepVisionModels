# -*- coding: utf-8 -*-
"""Malaria_Prediction_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LywLPH_oElKyIFX89FHXfL44XSh_boKq
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.layers import InputLayer, Conv2D, MaxPool2D, BatchNormalization
from tensorflow.keras.losses import BinaryCrossentropy

dataset, dataset_info = tfds.load('malaria',
                                  with_info = True,
                                  as_supervised= True,
                                  shuffle_files= True,
                                  split=['train'])

def splits(dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO):
  DATASET_SIZE = len(dataset)
  train_dataset = dataset.take(int(TRAIN_RATIO* DATASET_SIZE))

  val_test_dataset = dataset.skip(int(TRAIN_RATIO* DATASET_SIZE))
  val_dataset = val_test_dataset.take(int(VAL_RATIO * DATASET_SIZE))

  test_dataset = val_test_dataset.skip(int(VAL_RATIO * DATASET_SIZE))
  return train_dataset, val_dataset, test_dataset

train_ratio = 0.8
val_ratio = 0.1
test_ratio = 0.1
train_dataset, val_dataset, test_dataset = splits(dataset[0], train_ratio, val_ratio, test_ratio)
print(list(train_dataset.take(1).as_numpy_iterator()),
      list(val_dataset.take(1).as_numpy_iterator()),list(test_dataset.take(1).as_numpy_iterator()))

for i, (image, label) in enumerate(train_dataset.take(12)):
  plt.figure(figsize=(10, 10))
  ax = plt.subplot(4, 4, i + 1)
  plt.imshow(image)
  plt.title(dataset_info.features['label'].int2str(label))
plt.axis('off')

dataset_info.features['label'].int2str(1)

size = 224
def resize_rescale(image, label):
  return tf.image.resize(image, (size, size))/255.0, label

train_dataset =  train_dataset.map(resize_rescale)
val_dataset =  val_dataset.map(resize_rescale)
test_dataset = test_dataset.map(resize_rescale)
train_dataset

for data in train_dataset.take(1):
  print(image, label)

batch_size = 32
train_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration=True).batch(batch_size).prefetch(tf.data.AUTOTUNE)

val_dataset = val_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration=True).batch(batch_size).prefetch(tf.data.AUTOTUNE)

val_dataset

train_dataset

for data in train_dataset.take(1):
  print(data)

model = tf.keras.Sequential([
    InputLayer(input_shape=(size, size, 3)),
    Conv2D(5, 3, activation='relu'),
    BatchNormalization(),
    MaxPool2D(pool_size = 2,strides = 2),
    Conv2D(12, 3, activation='relu'),
    BatchNormalization(),
    MaxPool2D(pool_size = 2,strides = 2),
    Flatten(),
    Dense(100, activation='relu'),
    BatchNormalization(),
    Dense(10, activation='relu'),
    Dense(1, activation='sigmoid'),

])

model.summary()

y_true = [0,1,0,0]
y_pred = [0.6, 0.51, 0.94, 1]
bce = tf.keras.losses.BinaryCrossentropy()
bce(y_true, y_pred)

model.compile(optimizer = Adam(learning_rate=0.01),
                    loss = BinaryCrossentropy(),
                    metrics = 'accuracy')

history = model.fit(train_dataset, validation_data=val_dataset, epochs = 20, verbose = 1)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model_loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train_loss', 'val_loss'])
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model_accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train_accuracy', 'val_accuracy'])
plt.show()

test_dataset = test_dataset.batch(1)

model.evaluate(test_dataset)

def paraside_or_not(x):
  if(x < 0.5):
    return str('P')
  else:
    return str('U')

for i, (image, label) in enumerate(test_dataset.take(9)):
  ax = plt.subplot(3, 3, i + 1)
  plt.imshow(image[0])
  plt.title(str(paraside_or_not(label.numpy()[0])) + ":" +str(paraside_or_not(model.predict(image)[0][0])))
  plt.axis('off')

from sklearn.metrics import confusion_matrix
import seaborn as sns

true_labels = []
predicted_labels = []
test = 100
start  = 0
for image, label in test_dataset:
  if start == test:
    break
  start += 1
  true_labels.append(label.numpy()[0])
  predicted_labels.append(round(model.predict(image)[0][0]))

cm = confusion_matrix(true_labels, predicted_labels)

sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

model.save("SavedModel")