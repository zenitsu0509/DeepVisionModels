{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange"
      ],
      "metadata": {
        "id": "6Gd_vOLuiS7N"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, in_channels=1, patch_size=7, emb_size=64, img_size=28):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
        "            Rearrange('b e (h) (w) -> b (h w) e')\n",
        "        )\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_size))\n",
        "        self.pos_embedding = nn.Parameter(torch.randn((img_size // patch_size) ** 2 + 1, emb_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, _, _, _ = x.shape\n",
        "        x = self.projection(x)\n",
        "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
        "        x = torch.cat([cls_tokens, x], dim=1)\n",
        "        x += self.pos_embedding\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "n3RcMt6klrAk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, emb_size, num_heads):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        self.qkv = nn.Linear(emb_size, emb_size * 3)\n",
        "        self.fc = nn.Linear(emb_size, emb_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        qkv = self.qkv(x).chunk(3, dim=-1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.num_heads), qkv)\n",
        "        attn = torch.einsum('bhid,bhjd->bhij', q, k) / (self.emb_size ** (1/2))\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        out = torch.einsum('bhij,bhjd->bhid', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        return self.fc(out)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, emb_size, num_heads, forward_expansion=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadSelfAttention(emb_size, num_heads)\n",
        "        self.norm1 = nn.LayerNorm(emb_size)\n",
        "        self.norm2 = nn.LayerNorm(emb_size)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(emb_size, forward_expansion * emb_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(forward_expansion * emb_size, emb_size)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_out = self.attention(x)\n",
        "        x = self.norm1(x + self.dropout(attn_out))\n",
        "        ff_out = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_out))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "XQ4MFOkPltxD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=10, emb_size=64, num_heads=4, depth=6, patch_size=7, img_size=28):\n",
        "        super().__init__()\n",
        "        self.patch_embedding = PatchEmbedding(in_channels, patch_size, emb_size, img_size)\n",
        "        self.transformer = nn.Sequential(\n",
        "            *[TransformerBlock(emb_size, num_heads) for _ in range(depth)]\n",
        "        )\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(emb_size),\n",
        "            nn.Linear(emb_size, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)\n",
        "        x = self.transformer(x)\n",
        "        return self.mlp_head(x[:, 0])\n"
      ],
      "metadata": {
        "id": "mkNjWyEPl9pa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_vit(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch}, Loss: {total_loss / len(train_loader)}')\n",
        "\n",
        "def test_vit(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = correct / len(test_loader.dataset)\n",
        "    print(f'Test Loss: {test_loss}, Accuracy: {accuracy * 100}%')\n"
      ],
      "metadata": {
        "id": "PkL_NrVjmBYL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "    batch_size = 64\n",
        "    lr = 0.001\n",
        "    epochs = 10\n",
        "\n",
        "\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    model = VisionTransformer().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_vit(model, device, train_loader, optimizer, criterion, epoch)\n",
        "        test_vit(model, device, test_loader, criterion)\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), \"vit_mnist_model.pth\")\n",
        "    print(\"Model saved as vit_mnist_model.pth\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKxjHuc2mFFB",
        "outputId": "23422db5-3a0c-440d-e683-a2a513c9daa6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:10<00:00, 939688.81it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 131824.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:06<00:00, 244154.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3983799.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch 1, Loss: 0.3978350591887511\n",
            "Test Loss: 0.0020725001292303206, Accuracy: 95.75%\n",
            "Epoch 2, Loss: 0.13459080051003233\n",
            "Test Loss: 0.00194347941307351, Accuracy: 96.03%\n",
            "Epoch 3, Loss: 0.10372034123123709\n",
            "Test Loss: 0.0012858115376671777, Accuracy: 97.43%\n",
            "Epoch 4, Loss: 0.08513541262584931\n",
            "Test Loss: 0.0014866813399945385, Accuracy: 97.11%\n",
            "Epoch 5, Loss: 0.07552716850679415\n",
            "Test Loss: 0.0014613713509519584, Accuracy: 97.08%\n",
            "Epoch 6, Loss: 0.06752264775437063\n",
            "Test Loss: 0.0010180691562592984, Accuracy: 97.99%\n",
            "Epoch 7, Loss: 0.06294518103028761\n",
            "Test Loss: 0.00104467077270383, Accuracy: 98.00999999999999%\n",
            "Epoch 8, Loss: 0.05711004600191473\n",
            "Test Loss: 0.0010373986833379604, Accuracy: 98.02%\n",
            "Epoch 9, Loss: 0.05337616038654667\n",
            "Test Loss: 0.0008836555976886303, Accuracy: 98.21%\n",
            "Epoch 10, Loss: 0.047576574115718064\n",
            "Test Loss: 0.000912204745481722, Accuracy: 98.17%\n",
            "Model saved as vit_mnist_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BNtEfGgTmH9Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}